<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: utilities | Jake McCrary]]></title>
  <link href="https://jakemccrary.com/blog/categories/utilities/atom.xml" rel="self"/>
  <link href="https://jakemccrary.com/"/>
  <updated>2020-04-29T22:02:48-05:00</updated>
  <id>https://jakemccrary.com/</id>
  <author>
    <name><![CDATA[Jake McCrary]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Auto-syncing a git repository]]></title>
    <link href="https://jakemccrary.com/blog/2020/02/25/auto-syncing-a-git-repository/"/>
    <updated>2020-02-25T21:09:00-06:00</updated>
    <id>https://jakemccrary.com/blog/2020/02/25/auto-syncing-a-git-repository</id>
    <content type="html"><![CDATA[<p>I&rsquo;m currently keep notes on my computer using plain text and <a href="https://orgmode.org/">Org mode</a>.</p>

<p>I keep my notes in a git repository in my home directory, <code>~/org/</code>.
I want my notes to be synced between my computers without me thinking about it.
Historically, I&rsquo;ve reached for something like Google Drive or Dropbox to do this but this time I reached for git and GitHub.</p>

<p>Below is the script that I ended up cobbling together from various sources found online.
The script pushes and pulls changes from a remote repository and works on my macOS and linux machines.</p>

<p>The loop starting on line 38 does the work.
Whenever a file-watcher notices a change or 10 minutes passes, the loop pulls changes from a remote repository, commits any local changes, and pushes to the remote repository.
The lines before this are mostly checking that needed programs exist on the host.</p>

<p>I keep this running in a background terminal and I check periodically to confirm it is still running.
I could do something fancier but this isn&rsquo;t a critical system and the overhead of checking every couple days is nearly zero.
Most of the time checking happens by accident when I accidentally maximize the terminal that runs the script.</p>

<p>I&rsquo;ve been using this script for a long time now and I&rsquo;ve found it quite useful. I hope you do too.</p>

<pre><code class="bash">#!/bin/bash

set -e

TARGETDIR="$HOME/org/"

stderr () {
    echo "$1" &gt;&amp;2
}

is_command() {
    command -v "$1" &amp;&gt;/dev/null
}

if [ "$(uname)" != "Darwin" ]; then
    INW="inotifywait";
    EVENTS="close_write,move,delete,create";
    INCOMMAND="\"$INW\" -qr -e \"$EVENTS\" --exclude \"\.git\" \"$TARGETDIR\""
else # if Mac, use fswatch
    INW="fswatch";
    # default events specified via a mask, see
    # https://emcrisostomo.github.io/fswatch/doc/1.14.0/fswatch.html/Invoking-fswatch.html#Numeric-Event-Flags
    # default of 414 = MovedTo + MovedFrom + Renamed + Removed + Updated + Created
    #                = 256 + 128+ 16 + 8 + 4 + 2
    EVENTS="--event=414"
    INCOMMAND="\"$INW\" --recursive \"$EVENTS\" --exclude \"\.git\" --one-event \"$TARGETDIR\""
fi

for cmd in "git" "$INW" "timeout"; do
    # in OSX: `timeout` =&gt; brew install coreutils
    # in OSX: `fswatch` =&gt; brew install fswatch
    is_command "$cmd" || { stderr "Error: Required command '$cmd' not found"; exit 1; }
done

cd "$TARGETDIR"
echo "$INCOMMAND"

while true; do
    eval "timeout 600 $INCOMMAND" || true
    git pull
    sleep 5
    STATUS=$(git status -s)
    if [ -n "$STATUS" ]; then
        echo "$STATUS"
        echo "commit!"
        git add .
        git commit -m "autocommit"
        git push origin
    fi
done
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using comm to verify file content matches]]></title>
    <link href="https://jakemccrary.com/blog/2017/05/29/using-comm-to-verify-matching-content/"/>
    <updated>2017-05-29T10:45:00-05:00</updated>
    <id>https://jakemccrary.com/blog/2017/05/29/using-comm-to-verify-matching-content</id>
    <content type="html"><![CDATA[<p>I recently found myself in a situation where I needed to confirm that a process took in a tab separated file, did some processing, and then output a new file containing the original columns with some additional ones. The feature I was adding allowed the process to die and restart while processing the input file and pick up where it left off.</p>

<p>I needed to confirm the output had data for every line in the input. I reached to the command line tool <code>comm</code>.</p>

<p>Below is a made up input file.</p>

<pre><code>UNIQUE_ID   USER
1   38101838
2   19183819
3   19123811
4   10348018
5   19881911
6   29182918
</code></pre>

<p>And here is some made up output.</p>

<pre><code>UNIQUE_ID   USER    MESSAGE
1   38101838    A01
2   19183819    A05
3   19123811    A02
4   10348018    A01
5   19881911    A02
6   29182918    A05
</code></pre>

<p>With files this size, it would be easy enough to check visually. In my testing, I was dealing with files that had thousands of lines. This is too many to check by hand. It is a perfect amount for <code>comm</code>.</p>

<p><a href="https://en.wikipedia.org/wiki/Comm">comm</a> reads two files as input and then outputs three columns. The first column contains lines found only in the first file, the second column contains lines only found in the second, and the last column contains lines in both. If it is easier for you to think about it as set operations, the first two columns are similar to performing two set differences and the third is similar to set intersection. Below is an example adapted from Wikipedia showing its behavior.</p>

<pre><code>$ cat foo.txt
apple
banana
eggplant
$ cat bar.txt
apple
banana
banana
zucchini
$ comm foo.txt bar.txt
                  apple
                  banana
          banana
eggplant
          zucchini
</code></pre>

<p>So how is this useful? Well, you can also tell <code>comm</code> to suppress outputting specific columns.  If we send the common columns from the input and output file to <code>comm</code> and suppress <code>comm</code>&rsquo;s third column then anything printed to the screen is a problem. Anything printed to the screen was found in one of the files and not the other. We&rsquo;ll select the common columns using cut and, since comm expects input to be sorted, then sort using <code>sort</code>. Let&rsquo;s see what happens.</p>

<pre><code>$ comm -3 &lt;(cut -f 1,2 input.txt | sort) &lt;(cut -f 1,2 output.txt | sort)
$
</code></pre>

<p>Success! Nothing was printed to the console, so there is nothing unique in either file.</p>

<p><code>comm</code> is a useful tool to have in your command line toolbox.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Better command history in your shell]]></title>
    <link href="https://jakemccrary.com/blog/2016/09/28/better-command-history-in-your-shell/"/>
    <updated>2016-09-28T11:42:00-05:00</updated>
    <id>https://jakemccrary.com/blog/2016/09/28/better-command-history-in-your-shell</id>
    <content type="html"><![CDATA[<p>My ideal command history would let me search the history of every
shell but when I hit the up arrow it would only cycle through my
current shell&rsquo;s history. In February, I was able to achieve this setup
in large part because of a utility
called <a href="https://github.com/dvorka/hstr">hstr</a>.</p>

<h2>What is <code>hstr</code>?</h2>

<p>hstr is a neat Bash and Zsh utility that lets you easily search, view,
and manage your command history. hstr provides a tool named <code>hh</code> that
provides a text interface for manipulating your command
history. To see what it looks like check out
the <a href="https://github.com/dvorka/hstr/blob/master/README.md">README</a> and
this <a href="https://www.youtube.com/watch?v=sPF29NyXe2U">video</a> tutorial. If
you are running OS X and use Homebrew you can install it by running <code>brew
install hh</code>.</p>

<h2>Making global history searchable but arrows cycle through local history</h2>

<p>hstr is a neat tool but my favorite part of my setup is how the global
command history is searchable but only a shell&rsquo;s local history is
cycled through with the arrow keys. This is achieved by manipulating
where history is written and tweaking some environment variables.</p>

<p>The first step is to change your <code>$PROMPT_COMMAND</code> to append your
shell&rsquo;s history to a global history file. Below is the snippet that
does this from my <code>.bashrc</code> file.</p>

<pre><code># Whenever a command is executed, write it to a global history
PROMPT_COMMAND="history -a ~/.bash_history.global; $PROMPT_COMMAND"
</code></pre>

<p>The next step is to bind a keystroke to run <code>hh</code>, which is what hstr
provides, with <code>$HISTFILE</code> pointing to <code>~/.bash_history.global</code>. I
wanted to fully replace the default command history searching (and I
use Emacs style keyboard shortcuts) so I&rsquo;ve bound these actions to ctrl-r.</p>

<pre><code class="bash"># On C-r set HISTFILE and run hh
bind -x '"\C-r": "HISTFILE=~/.bash_history.global hh"'
</code></pre>

<p>With those two additions to my <code>.bashrc</code> I&rsquo;ve achieved my ideal
command history searching. When I hit ctrl-r I&rsquo;m searching all of my
history and yet I only cycle through a shell&rsquo;s local history with the
arrow keys. This small addition<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> made my command line productivity
higher.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>My setup was inspired by <a href="https://unix.stackexchange.com/questions/200225/search-history-from-multiple-bash-session-only-when-ctrl-r-is-used-not-when-a">this</a> StackExchange post.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Utilities I like: autojump]]></title>
    <link href="https://jakemccrary.com/blog/2011/07/25/utilities-i-like-autojump/"/>
    <updated>2011-07-25T00:00:00-05:00</updated>
    <id>https://jakemccrary.com/blog/2011/07/25/utilities-i-like-autojump</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/joelthelion/autojump">autojump</a> is a nifty command line tool that enables quicker jumping between directories. I&rsquo;ve been using it for a few months now and miss it when I work other machines.</p>

<p>To jump to a directory you type <code>j SUBSTRING_OF_DIR</code>. Example:</p>

<pre><code class="bash">    $ pwd
    /Users/jmccrary
    $ j jake
    /Users/jmccrary/src/github/jakemcc/jakemccrary.com
    $ pwd
    /Users/jmccrary/src/github/jakemcc/jakemccrary.com
</code></pre>

<p>Above I jumped from my home directory to the root of this website&rsquo;s code. Being able to jump between directories by just remembering a name (or part of a name) is great. This frees me from having to remember full paths or set up aliases.</p>

<p>autojump works by keeping a database of &ldquo;time&rdquo; spent in directories and jumps to the most frequently visited one that match <code>SUBSTRING_OF_DIR</code>. If you are curious as to what that database looks like the tool <code>jumpstat</code> will give you a view.</p>

<p>I used to set up aliases for jumping between projects but now that I&rsquo;ve trained myself to use autojump I don&rsquo;t think I&rsquo;ll ever go back. Not having to do any extra work besides simply entering the root directory of new projects to setup efficient directory movement is great. I think that if you give it a shot for a while you&rsquo;ll find the same benefits.</p>

<p>If you are on a Mac and use <a href="https://github.com/mxcl/homebrew">homebrew</a> you can install by doing <code>brew install autojump</code>. For other platforms check out the <a href="https://github.com/joelthelion/autojump">github</a> page.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A simple way of testing disconnect logic]]></title>
    <link href="https://jakemccrary.com/blog/2011/06/28/a-simple-way-of-testing-disconnect-logic/"/>
    <updated>2011-06-28T00:00:00-05:00</updated>
    <id>https://jakemccrary.com/blog/2011/06/28/a-simple-way-of-testing-disconnect-logic</id>
    <content type="html"><![CDATA[<p>I&rsquo;m guessing that software you write connects to some other server. I&rsquo;m also guessing that how it handles disconnects is tested (if ever tested) by either killing the process it connects to or by pulling out your network cable. I recently stumbled across a nifty Linux command line tool that makes causing disconnects significantly easier.</p>

<p>This tool is <a href="http://linux.die.net/man/8/tcpkill">tcpkill</a>. To use <code>tcpkill</code> you specify an interface and a <a href="http://linux.die.net/man/8/tcpdump">tcpdump</a> style filter and it kills traffic on that interface that matches the filter.</p>

<p>For example, if your application has a connection to 192.168.1.130, then to force a disconnect you would execute <code>tcpkill -i eth0 host 192.168.1.130</code>.</p>

<p><code>tcpkill</code> can be used for more than forcing disconnects. It can also be used as a simple website filter. If <a href="http://stackoverflow.com">Stack Overflow</a> wastes too much of your time then you could simply leave <code>tcpkill -i eth0 host stackoverflow.com</code> running and enjoy your increased productivity.</p>

<p><code>tcpkill</code> is a pretty useful tool. If you want to install it in Ubuntu it is found in the dsniff package (<code>apt-get install dsniff</code>).</p>
]]></content>
  </entry>
  
</feed>
