<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: testing | Jake McCrary]]></title>
  <link href="http://jakemcc.github.com/blog/categories/testing/atom.xml" rel="self"/>
  <link href="http://jakemcc.github.com/"/>
  <updated>2012-04-13T22:16:09-05:00</updated>
  <id>http://jakemcc.github.com/</id>
  <author>
    <name><![CDATA[Jake McCrary]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Continuous testing with Clojure and expectations]]></title>
    <link href="http://jakemcc.github.com/blog/2011/12/16/continuous-testing-with-clojure-and-expectations/"/>
    <updated>2011-12-16T09:30:00-06:00</updated>
    <id>http://jakemcc.github.com/blog/2011/12/16/continuous-testing-with-clojure-and-expectations</id>
    <content type="html"><![CDATA[<p>I've recently started using <a href="http://jayfields.com/">Jay Fields'</a> Clojure testing library, <a href="https://github.com/jaycfields/expectations"><code>expectations</code></a>. I'm not going to explain <code>expectations</code>, Jay already did a great job on his <a href="http://blog.jayfields.com/2011/11/clojure-expectations-introduction.html">blog</a>, but I will quote its <a href="https://github.com/jaycfields/expectations">Github</a> page.</p>

<blockquote><p>expectations is a minimalist's testing framework</p></blockquote>

<p>The above quote is absolutely true, which is one of the major reasons I'm liking <code>expectations</code>. It hasn't been all sunshine though, when I first started using it I had a major problem. It slowed down my usual Clojure workflow.</p>

<p>Up until this point I had stuck to using <code>clojure.test</code>. Combined with emacs, slime, swank, and <code>clojure-test-mode</code> I found the time between making a change to code and running tests to be minimal.</p>

<p>When I switched to <code>expectations</code> the time it took between making a code change and running tests increased. With <code>expectations</code> I couldn't reevaluate my buffer to get the new tests in my repl environment. Doing so caused the new tests to be there along with the old tests. This meant I needed to switch to the command line to run my tests. This caused me to incur the startup costs of the jvm simply to run my expectations (tests). This was a huge cost compared to what I was used to before.</p>

<h2>Introducing <code>lein-autoexpect</code></h2>

<p>To fix my problem I wrote <a href="https://github.com/jakemcc/lein-autoexpect"><code>lein-autoexpect</code></a>. <code>lein-autoexpect</code> is a <a href="https://github.com/technomancy/leiningen/"><code>Leiningen</code></a> plugin that monitors a project's source and test directory and when a Clojure file changes it reloads the affected namespaces and runs all the expectations. Using this plugin my turn around time from modifying code to running all of my expectations is practically nothing. Without the cost of the jvm startup there is practically no time wasted between when code is saved and tests are run.</p>

<p>To use <code>lein-autoexpect</code> simply add <code>[lein-autoexpect "0.0.2"]</code> to your <code>project.clj</code> file and fetch the dependency. Then at the command line run <code>lein autoexpect</code>. You'll see your tests run and then it will just hang there, eagerly waiting for code to change.</p>

<p>``` bash</p>

<pre><code>$ lein autoexpect
*********************************************
*************** Running tests ***************
Ran 3 tests containing 3 assertions in 16 msecs
0 failures, 0 errors.
</code></pre>

<p>```</p>

<p>Next time you end up saving you'll see your tests run again and the following example output appears.</p>

<p>``` bash</p>

<pre><code>*********************************************
*************** Running tests ***************
Ran 4 tests containing 4 assertions in 3 msecs
0 failures, 0 errors.
</code></pre>

<p>```</p>

<p><code>lein-autoexpect</code> tries to clearly delimit each test session with the banner made of <code>*</code>. This helps keep different runs separate when scrolling through your terminal.</p>

<p>This style of testing is called <a href="http://blog.objectmentor.com/articles/2007/09/20/continuous-testing-explained">continuous testing</a>. If you haven't tried it, I would highly recommend giving it a shot. Even just using it for the last few days changed how I think testing should be done.</p>

<p>Source can be found on <a href="https://github.com/jakemcc/lein-autoexpect">Github</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A simple way of testing disconnect logic]]></title>
    <link href="http://jakemcc.github.com/blog/2011/06/28/a-simple-way-of-testing-disconnect-logic/"/>
    <updated>2011-06-28T00:00:00-05:00</updated>
    <id>http://jakemcc.github.com/blog/2011/06/28/a-simple-way-of-testing-disconnect-logic</id>
    <content type="html"><![CDATA[<p>I'm guessing that software you write connects to some other server. I'm also guessing that how it handles disconnects is tested (if ever tested) by either killing the process it connects to or by pulling out your network cable. I recently stumbled across a nifty Linux command line tool that makes causing disconnects significantly easier.</p>

<p>This tool is <a href="http://linux.die.net/man/8/tcpkill">tcpkill</a>. To use <code>tcpkill</code> you specify an interface and a <a href="http://linux.die.net/man/8/tcpdump">tcpdump</a> style filter and it kills traffic on that interface that matches the filter.</p>

<p>For example, if your application has a connection to 192.168.1.130, then to force a disconnect you would execute <code>tcpkill -i eth0 host 192.168.1.130</code>.</p>

<p><code>tcpkill</code> can be used for more than forcing disconnects. It can also be used as a simple website filter. If <a href="http://stackoverflow.com">Stack Overflow</a> wastes too much of your time then you could simply leave <code>tcpkill -i eth0 host stackoverflow.com</code> running and enjoy your increased productivity.</p>

<p><code>tcpkill</code> is a pretty useful tool. If you want to install it in Ubuntu it is found in the dsniff package (<code>apt-get install dsniff</code>).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Generating test cases in Clojure]]></title>
    <link href="http://jakemcc.github.com/blog/2011/01/18/generating-test-cases-in-clojure/"/>
    <updated>2011-01-18T00:00:00-06:00</updated>
    <id>http://jakemcc.github.com/blog/2011/01/18/generating-test-cases-in-clojure</id>
    <content type="html"><![CDATA[<p>Recently I was writing some data mining Clojure code which needed to parse a log file and do some transforms of the data. Some of the transforms were dependent on data found across multiple lines. There was no ordering or proximity guarantees to these lines.</p>

<p>This required the code to handle a variety of situations. After writing a couple simple tests and getting those passing I wanted to more extensively test my solution. I was lazy though and did not want to hand code all of the potential orderings.  Enter <code>permutations</code>.</p>

<p><code>permutations</code> is a function out of <a href="http://clojure.github.com/clojure-contrib/combinatorics-api.html">clojure.contrib.combinatorics</a>. As the name suggests, you give it a collection and it returns a lazy sequence containing all the different permutations of the elements in that collection. An example is below.</p>

<p>``` clojure</p>

<pre><code>user&gt;(ns generate)
generate&gt;(use '[clojure.contrib.combinatorics :only [permutations]])
nil
generate&gt; (permutations [:a :b :c])
((:a :b :c) (:a :c :b) (:b :a :c) (:b :c :a) (:c :a :b) (:c :b :a))
</code></pre>

<p>```</p>

<p>You can already see where this is going. I was able to use <code>permutations</code> to generate all the potential different orderings of the input. This saved me the trouble of having to do that by hand.</p>

<p>One difficulty of generating test inputs pragmatically is telling what sort of inputs caused it to fail. To get around this I used the rarely used (at least in code I'm working on) second argument of <a href="http://clojure.github.com/clojure/clojure.test-api.html#clojure.test/is">clojure.test's</a> <code>is</code>. This second argument is a message that prints on a failure.</p>

<p>Below is a contrived example of using <code>permutations</code> to test an obviously wrong <code>silly-add</code> function. <code>silly-add</code> is defined below.</p>

<p>``` clojure</p>

<pre><code>generate&gt; (defn silly-add
              [x &amp; xs]
              (if (zero? x)
                  (apply + 40 xs)
                  (apply + x xs)))
#'generate/silly-add
</code></pre>

<p>```</p>

<p>Below is a test that uses <code>permutations</code> to exercise <code>silly-add</code> with all the potential orderings three input numbers. Note that it takes advantage of the second argument to <code>is</code>. Without this we would not know what input caused the failure.</p>

<p>``` clojure</p>

<pre><code>generate&gt; (use 'clojure.test)
nil
generate&gt; (deftest generate-some-tests
            (doseq [input (permutations [1 0 9])]
                   (is (= 10 (apply silly-add input))
                       (str "Failed on input: " (seq input)))))
#'generate/generate-some-tests
</code></pre>

<p>```</p>

<p>Running the test we see that there is clearly an error.</p>

<p>``` clojure</p>

<pre><code>generate&gt; (run-tests)
Testing generate

FAIL in (generate-some-tests) (NO_SOURCE_FILE:1)
Failed on input: (0 1 9)
expected: (= 10 (apply silly-add input))
  actual: (not (= 10 50))

FAIL in (generate-some-tests) (NO_SOURCE_FILE:1)
Failed on input: (0 9 1)
expected: (= 10 (apply silly-add input))
  actual: (not (= 10 50))
</code></pre>

<p>```</p>

<p><code>permutations</code> saved me a bit of time and let me test some situations that I otherwise would not have tested. This actually exposed a subtle bug in my code. Hopefully it can do the same for you.</p>
]]></content>
  </entry>
  
</feed>
