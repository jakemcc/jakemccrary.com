<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Jake McCrary's articles on testing]]></title>
  <link href="https://jakemccrary.com/atom.xml" rel="self"/>
  <link href="https://jakemccrary.com/"/>
  <updated>2025-02-03T01:19:30+00:00</updated>
  <id>https://jakemccrary.com/</id>
  <author>
    <name><![CDATA[Jake McCrary]]></name>
  </author>
  <entry>
    <id>https://jakemccrary.com/blog/2021/09/11/tests-can-act-as-living-documentation/index.html</id>
    <link href="https://jakemccrary.com/blog/2021/09/11/tests-can-act-as-living-documentation/index.html"/>
    <title><![CDATA[Tests are living documentation]]></title>
    <updated>2021-09-11T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>Tests can serve many purposes.</p><p>You might write tests as a way of driving the design of your software. Other tests might be written in response to a discovered bug and, if written first, those tests you know when you've fixed the bug and act as guardrails preventing the reintroduction of that bug. Tests can also be used to confirm you haven't changed behavior while refactoring.</p><p>Tests can also be used as documentation. Unlike non-executable documentation, tests will always match the implementation's behavior.</p><p>An example in a comment or other documentation deserves to be in a test. Take the following sketch of a Clojure function:</p><pre><code class="language-clojure">&#40;defn confobulate
  &quot;Takes a string and transforms it to the confobulated form. Examples:
  - \&quot;alice\&quot; -&gt; \&quot;EcilA\&quot;
  - \&quot;//yolo1\&quot; -&gt; \&quot;//oneOloY\&quot;
  &quot;
  &#91;s&#93;
  &#40;-&gt; s
      ;; insert some work here, not going to implement this
      &#41;&#41;
</code></pre><p>The docstring has examples in it to aid humans in understanding its behavior. These examples are useful! But they stop being useful and start being dangerous when they stop being accurate.</p><p>We can use unit tests to keep examples like this correct. You can write comments near the assertions letting future readers know about the documentation that needs to be updated if behavior changes.</p><pre><code class="language-clojure">&#40;deftest confobulate-should-ignore-slashes
  ;; If this assertion changes the docstring needs to be updated
  &#40;is &#40;= &quot;//oneOloY&quot; &#40;confobulate &quot;//yolo1&quot;&#41;&#41;&#41;&#41;

&#40;deftest confobulate-reverses-and-capitalizes
  ;; If this assertion changes the docstring needs to be updated
  &#40;is &#40;= &quot;alice&quot; &#40;confobulate &quot;EcilA&quot;&#41;&#41;&#41;&#41;
</code></pre><p>Any example in a comment or other non-executable documentation should be an assertion in a unit test. You've already taken the time to document the behavior; take the time to figure out how to document it in a way that will fail if the behavior changes.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2021/08/07/improve-your-tests-by-picking-better-constants/index.html</id>
    <link href="https://jakemccrary.com/blog/2021/08/07/improve-your-tests-by-picking-better-constants/index.html"/>
    <title><![CDATA[Improve your tests by picking better constants]]></title>
    <updated>2021-08-07T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>The constants you use in unit tests matter. Like test and variable names, they can improve the readability of your code and make it easier to understand test failures.</p><p>Imagine the following.</p><p>A new developer joins your team and asks a question about how the code resolves config values. You are unsure of the details so you pair up with the new teammate to dig into the code.</p><p>You know the codebase uses a relatively simple key-value pair concept for configuration. It reads keys and values from a known files and, based on some rules, either ignores or overrides values when keys are duplicated across files.</p><p><code>config-value</code> is the function that looks up the value for a particular configuration key, represented as a <code>string</code>. This function takes three arguments: an in-memory representation of the configuration files, the key to lookup, and the mode to operate in. You know the mode is important in influencing how config resolution works but you don't remember the details.</p><p>Luckily for you and your pair, the codebase has plenty of unit tests. The two of you dive in and look at some tests, hoping to understand how config resolution works.</p><pre><code class="language-clojure">&#40;def config {&quot;scratch.conf&quot; {&quot;a&quot; &quot;1&quot;}

             &quot;development.conf&quot; {&quot;a&quot; &quot;2&quot;
                                 &quot;b&quot; &quot;2&quot;}

             &quot;application.conf&quot; {&quot;a&quot; &quot;3&quot;
                                 &quot;b&quot; &quot;3&quot;
                                 &quot;c&quot; &quot;3&quot;}}&#41;

&#40;deftest handles-overrides-in-dev-mode
  &#40;is &#40;= &quot;1&quot; &#40;config-value config &quot;a&quot; :dev&#41;&#41;&#41;
  &#40;is &#40;= &quot;2&quot; &#40;config-value config &quot;b&quot; :dev&#41;&#41;&#41;
  &#40;is &#40;= &quot;3&quot; &#40;config-value config &quot;c&quot; :dev&#41;&#41;&#41;&#41;

&#40;deftest handles-overrides-in-prod-mode
  &#40;is &#40;= &quot;3&quot; &#40;config-value config &quot;a&quot; :prod&#41;&#41;&#41;
  &#40;is &#40;= &quot;3&quot; &#40;config-value config &quot;b&quot; :prod&#41;&#41;&#41;
  &#40;is &#40;= &quot;3&quot; &#40;config-value config &quot;c&quot; :prod&#41;&#41;&#41;&#41;
</code></pre><p>It is great that these tests exist but they could be clearer. They aren't terrible but you have to work a bit understand what is happening.</p><p>When reading <code>&#40;= &quot;2&quot; &#40;config-value config &quot;b&quot; :dev&#41;&#41;</code>, what does <code>&quot;2&quot;</code> represent? What does <code>&quot;b&quot;</code> mean? You have to either keep the value of <code>config</code> in your brain or keep glancing up in the file to recall what it is.</p><p>This isn't great. This adds cognitive overhead that doesn't need to be there.</p><p>There are a few ways these tests could be improved One way is through using better constants. Let's do a quick rewrite.</p><pre><code class="language-clojure">&#40;def config {&quot;scratch.conf&quot; {&quot;in dev+app+scratch&quot; &quot;from scratch&quot;}

             &quot;development.conf&quot; {&quot;in dev+app+scratch&quot; &quot;from development&quot;
                                 &quot;in dev+app&quot; &quot;from development&quot;}

             &quot;application.conf&quot; {&quot;in dev+app+scratch&quot; &quot;from application&quot;
                                 &quot;in dev+app&quot; &quot;from application&quot;
                                 &quot;in app&quot; &quot;from application&quot;}}&#41;

&#40;deftest handles-overrides-in-dev-mode
  &#40;is &#40;= &quot;from scratch&quot; &#40;config-value config &quot;in dev+app+scratch&quot; :dev&#41;&#41;&#41;
  &#40;is &#40;= &quot;from development&quot; &#40;config-value config &quot;in dev+app&quot; :dev&#41;&#41;&#41;
  &#40;is &#40;= &quot;from application&quot; &#40;config-value config &quot;in app&quot; :dev&#41;&#41;&#41;&#41;

&#40;deftest handles-overrides-in-prod-mode
  &#40;is &#40;= &quot;from application&quot; &#40;config-value config &quot;in dev+app+scratch&quot; :prod&#41;&#41;&#41;
  &#40;is &#40;= &quot;from application&quot; &#40;config-value config &quot;in dev+app&quot; :prod&#41;&#41;&#41;
  &#40;is &#40;= &quot;from application&quot; &#40;config-value config &quot;in app&quot; :prod&#41;&#41;&#41;&#41;
</code></pre><p>These are the same tests but with different constants. Those constants make a huge difference. This change has made the tests more legible. You no longer need to remember the value of <code>config</code> or keep glancing up at it to understand the assertions in a test.</p><p>You can read <code>&#40;= &quot;from development&quot; &#40;config-value config &quot;in dev+app&quot; :dev&#41;&#41;</code> and have a pretty solid idea that you are looking up a key found in both <code>development.conf</code> and <code>application.conf</code> and while in <code>:dev</code> mode expect the value from <code>development.conf</code>.</p><p>The new constants provide clues about what the test expects. You can read and understand the assertions without keeping much state in your head.</p><p>This increases the legibility of the tests and is useful when a test fails. Which of the following is clearer?</p><pre><code>FAIL in &#40;handles-overrides-in-dev-mode&#41;
expected: &quot;2&quot;
  actual: &quot;3&quot;
    diff: - &quot;2&quot;
          + &quot;3&quot;
</code></pre><pre><code>FAIL in &#40;handles-overrides-in-dev-mode&#41;
expected: &quot;from development&quot;
  actual: &quot;from application&quot;
    diff: - &quot;from development&quot;
          + &quot;from application&quot;
</code></pre><p>The second one is clearer. You can read it and form a hypothesis about what might be broken.</p><p>Well chosen constants reduce the state a person needs to keep in their head. This makes tests easier to understand. Good constants also make test failures easier to understand. Just like good variable names, good constants increase the readability of our tests.</p><p>It is well worth placing some extra thought into the constants found in your tests.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2020/06/28/using-bazel-to-help-fix-flaky-tests/index.html</id>
    <link href="https://jakemccrary.com/blog/2020/06/28/using-bazel-to-help-fix-flaky-tests/index.html"/>
    <title><![CDATA[Using Bazel to help fix flaky tests]]></title>
    <updated>2020-06-28T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>Flaky tests are terrible. These are tests that pass or fail without anything changing in the code. They often pass the majority of the time and fail rarely. This makes them hard to detect and cause developers to often just run the tests again.</p><p>Flaky tests erode your team's confidence in your system. They cause folks to get in the habit of not trusting the output of tests. This discourages people from writing tests as they stop seeing them as something that improves quality and instead view them as a drag on productivity.</p><p>Flaky tests are often hard to fix. If they were easy to fix, they wouldn't have been flaky in the first place. One difficulty in fixing them is that the failures are often hard to reproduce.</p><p>Often, the first step in fixing a flaky test is to write a script to run the tests multiple times in a row. If you are using <a href='https://bazel.build/'>Bazel</a> as your build tool you don't need to write this.</p><p>Here is an example <code>bazel</code><a href='#fn-1' id='fnref1'><sup>1</sup></a> command for helping you recreate flaky test failures.</p><p><code>bazel test --test&#95;strategy=exclusive --test&#95;output=errors --runs&#95;per&#95;test=50 -t- //...</code></p><p>The above command is running all the test targets in a workspace and each flag is important.</p><ul><li><code>--runs&#95;per&#95;test=50</code> is telling Bazel to run each test 50 times.</li><li><code>--test&#95;output=errors</code> is telling Bazel to only print errors to your console.</li><li><code>-t-</code> is a shortcut for <code>--nocache&#95;test&#95;results</code> (or <code>--cache&#95;test&#95;results=no</code>).This flag tells Bazel to <strong>not</strong> cache the test results.</li><li><code>--test&#95;strategy=exclusive</code> will cause tests to be run serially.Without this, Bazel could run your test targets concurrently and if your tests aren't designed for this you may run into other failures.</li></ul><p>Flaky tests are terrible and you should try not to have them. Try your best to have reliable tests. <ol class='footnotes'><li id='fn-1'>I've written this while using Bazel 3.2.0. If you are reading this far in the future the flags may have changed.<a href='#fnref1'>&#8617;</a></li></ol></p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2019/03/20/breaking-change-and-more-in-lein-test-refresh-0-dot-24-dot-0/index.html</id>
    <link href="https://jakemccrary.com/blog/2019/03/20/breaking-change-and-more-in-lein-test-refresh-0-dot-24-dot-0/index.html"/>
    <title><![CDATA[Breaking change and more in lein-test-refresh 0.24.1]]></title>
    <updated>2019-03-20T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>Today I released <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a> <code>0.24.1</code><a href='#fn-1' id='fnref1'><sup>1</sup></a>. I don't always announce new lein-test-refresh versions with an article but this release breaks some existing behavior so I thought it was worth it.</p><p>Each of these changes is the direct result of interacting with four different <code>lein-test-refresh</code> users. Some of this took place on GitHub and others through email. Thanks to all of you for taking the time to think about improvements and notice oddities and bring them to my attention.</p><h3>Breaking change: Monitoring keystrokes to perform actions</h3><p>Prior to this release, if you hit Ctrl-D then STDIN reads an EOF and <code>test-refresh</code> would quit. With version 0.24.1, <code>test-refresh</code> no longer does that. Instead, it stops monitoring for input and just keeps running tests. Since it stops monitoring for input it no longer notices when you hit Enter to cause your tests to rerun. You can still stop <code>lein test-refresh</code> by sending a SIGINT with Ctrl-C.</p><p>This change was made because there is some combination of environments where if <code>test-refresh</code> execs <code>/bin/bash</code> then it receives an EOF on STDIN. Before this change, that means <code>test-refresh</code> would quit unexpectedly. Now it will keep going.</p><p>Thanks <a href='https://github.com/cloojure'>Alan Thompson</a> for bringing this to my attention and taking the time to help diagnose the problem.</p><h3>You can supply your own narrowing test selector</h3><p>Being able to tell <code>test-refresh</code> to narrow its focus by adding <code>:test-refresh/focus</code> as metadata on a test or namespace has quickly become a favorite feature of many users. Now you can configure a shorter keyword by specifying configuration in your profile. See the <a href='https://github.com/jakemcc/lein-test-refresh/blob/1b5165660d9e40d9394809a95b148ec758a6d56b/sample.project.clj#L61-L65'>sample project.clj</a> for how to set this up.</p><p>Thanks <a href='https://github.com/metametadata'>Yuri Govorushchenko</a> for the suggestion.</p><h3>Experimental: Run in a repl</h3><p>I've turned down this feature in the past but a narrower request came up and I thought it seemed useful. <code>test-refresh</code> now exposes a function you can call in a repl to run <code>test-refresh</code> in that repl. This makes the repl useless for any other task. To do this, first add <code>lein-test-refresh</code> as a dependency instead of a plugin to your project.clj. Then, require the namespace and call the function passing in one or more paths to your test directories. Example below.</p><pre><code class="language-clojure">user=&gt; &#40;require 'com.jakemccrary.test-refresh&#41;
nil
user=&gt; &#40;com.jakemccrary.test-refresh/run-in-repl &quot;test&quot;&#41;
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42; Running tests &#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
</code></pre><p><a href='https://github.com/jakemcc/lein-test-refresh/issues/80'>This request</a> was done so that you can run it in Cursive's repl and gain the ability to click on stacktraces. Thanks <a href='https://github.com/klauswuestefeld'>Klaus Wuestefeld</a> for bringing this up again with a really solid and focused use case.</p><h3>Better output on exceptions while reloading</h3><p>This was a <a href='https://github.com/jakemcc/lein-test-refresh/pull/81'>pull request</a> from <a href='https://github.com/minhtuannguyen'>Minh Tuan Nguyen</a>. Now figuring out where to look for the error will be a little easier.</p><h2>Thank you</h2><p>Thanks to all the users of lein-test-refresh. I've found it to be very valuable to the way I work and I'm very happy that others do as well. <ol class='footnotes'><li id='fn-1'>This was originally 0.24.0 but that had a bug in it. Sorry about that.<a href='#fnref1'>&#8617;</a></li></ol></p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2019/02/13/testing-asynchronous-javascript-with-jasmine/index.html</id>
    <link href="https://jakemccrary.com/blog/2019/02/13/testing-asynchronous-javascript-with-jasmine/index.html"/>
    <title><![CDATA[Testing asynchronous JavaScript with Jasmine]]></title>
    <updated>2019-02-13T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>I was recently adding a feature to an internal web UI that caught all unhandled JavaScript errors and reported them to the backend service. The implementation went smoothly with most of the effort spent figuring out how to test the code that was reporting the errors.</p><p>If the error reporting failed, I didn't want to trigger reporting another error or completely lose that error. I decided to log a reporting error to the console. I wanted to write a test showing that errors reporting errors were handled so that a future me, or another developer, didn't accidentally remove this special error handling and enable a never ending cycle of of reporting failed reporting attempts.</p><p>It took me a while to figure out how to do this. I searched the web and found various articles about using <a href='https://jasmine.github.io/'>Jasmine</a> to do async tests. They were helpful but I also wanted to mock out a function, <code>console.error</code>, and assert that it was called. None of the examples I found were explicit about doing something like this. I forget how many different approaches I tried, but it took a while to figure out the below solution.</p><p>Here is the code I wanted to test.</p><pre><code class="language-javascript">function reportEvent&#40;event&#41; {
  return fetch&#40;'/report-event', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify&#40;{name: 'ui name', ...event}&#41;
  }&#41;.catch&#40;function&#40;e&#41; { console.error&#40;'Problem reporting event:', e&#41;}&#41;;
}
</code></pre><p>It takes an incoming <code>event</code> object and merges it with a default value and posts that to the backing service. <code>fetch</code> returns a Promise and the code handles errors by calling <code>catch</code> on it and logging.</p><p>Below is what I eventually came up with for testing the error handling feature of <code>reportEvent</code>.</p><pre><code class="language-javascript">describe&#40;'reporting events', function&#40;&#41; {
  it&#40;'logs errors', &#40;done&#41; =&gt; {
    spyOn&#40;console, 'error'&#41;.and.callFake&#40;&#40;&#41; =&gt; {
      expect&#40;console.error&#41;.toHaveBeenCalled&#40;&#41;;
      done&#40;&#41;;
    }&#41;;
    spyOn&#40;window, 'fetch'&#41;.and.returnValue&#40;Promise.reject&#40;'error!'&#41;&#41;;
    reportEvent&#40;{level: 'WARN', msg: 'ERROR!'}&#41;;
  }&#41;;
}&#41;;
</code></pre><p>This uses <code>spyOn</code> to mock out <code>fetch</code> and <code>console.error</code>. The <code>fetch</code> call is told to return a rejected Promise. The <code>console.error</code> spy is a bit more interesting.</p><p>The <code>console.error</code> spy is told to call a fake function. That function asserts that the <code>console.error</code> spy has been called. More importantly, it also calls a <code>done</code> function. That <code>done</code> function is a callback passed to your test by Jasmine. Calling <code>done</code> signals that your async work is completed.</p><p>If <code>done</code> is never called then Jasmine will fail the test after some amount of time. By calling <code>done</code> in our <code>console.error</code> fake, we're able to signal to Jasmine that we've handled the rejected promise.</p><p>You don't actually need the <code>expect&#40;console.error&#41;.toHaveBeenCalled&#40;&#41;;</code> as <code>done</code> won't be called unless <code>console.error</code> has been called. If you don't have it though then Jasmine will complain there are no assertions in the test.</p><p>So there we have it, an example of using some of Jasmine's asynchronous test features with spies. I wish I had found an article like this when I started this task. Hopefully it saves you, and future me, some time.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2019/01/28/how-to-use-leiningen-test-selectors-to-filter-by-test-name/index.html</id>
    <link href="https://jakemccrary.com/blog/2019/01/28/how-to-use-leiningen-test-selectors-to-filter-by-test-name/index.html"/>
    <title><![CDATA[How to use Leiningen test selectors to filter by test name]]></title>
    <updated>2019-01-28T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p><!&ndash; Estimate: 30 minutes &ndash;> <!&ndash; First draft: 38 minutes &ndash;> <!&ndash; First edit: 13 minutes &ndash;> <!&ndash; Second edit: 8 minutes &ndash;></p><p>Leiningen test selectors are great. They allow you to filter what tests run by applying a function to the test's metadata. If that function returns a truthy value then that test will run. <a href='https://github.com/jakemcc/lein-test-refresh/blob/master/CHANGES.md#040'>lein-test-refresh</a> supports them and even includes a built in one for its <a href='https://github.com/jakemcc/lein-test-refresh#built-in-test-narrowing-test-selector'>focus feature</a>.</p><p>I was recently <a href='https://github.com/jakemcc/lein-test-refresh/issues/78'>asked</a> if test-refresh could support filtering tests using a regular expression against the name of a namespace or test. Lucky for me, test-refresh already supports this because of its support of test selectors.</p><p>Most of the examples of Leiningen test selectors show very simple functions that look for the existence of a keyword in the metadata. We can do more than that. We can write a predicate that does whatever we want with the metadata.</p><p>To take a look at a test's metadata, I generated a new project and looked at the generated default test file.</p><pre><code class="language-clojure">&#40;ns selector.core-test
  &#40;:require &#91;clojure.test :refer :all&#93;
            &#91;selector.core :refer :all&#93;&#41;&#41;

&#40;deftest a-test
  &#40;testing &quot;FIXME, I fail.&quot;
    &#40;is &#40;= 0 1&#41;&#41;&#41;&#41;
</code></pre><p>I then used my repl and to see what metadata was on the test.</p><pre><code class="language-clojure">selector.core-test&gt; &#40;meta #'a-test&#41;
{:test #function&#91;selector.core-test/fn--17267&#93;,
 :line 5,
 :column 1,
 :file &quot;/Users/jake/src/jakemcc/blog-examples/selector/test/selector/core&#95;test.clj&quot;,
 :name a-test,
 :ns #namespace&#91;selector.core-test&#93;}
</code></pre><p>Given the metadata above, I wrote the selector below which lets us select only integration tests.</p><pre><code class="language-clojure">:test-selectors {:integration &#40;fn &#91;m&#93;
                                &#40;or &#40;clojure.string/includes? &#40;str &#40;:ns m&#41;&#41;
                                                              &quot;integration&quot;&#41;
                                    &#40;clojure.string/includes? &#40;str &#40;:name m&#41;&#41;
                                                              &quot;integration&quot;&#41;&#41;&#41;}
</code></pre><p>You could write the above code is many different ways. Whatever you write, it needs to look for the existence of <code>integration</code> in either the test's name or namespace.</p><p>If you wanted to make <code>lein test</code> or <code>lein test-refresh</code> only run non-integration tests you can add a default test selector to the project.clj.</p><pre><code class="language-clojure">:test-selectors {:default &#40;fn &#91;m&#93;
                            &#40;not &#40;or &#40;clojure.string/includes? &#40;str &#40;:ns m&#41;&#41;
                                                               &quot;integration&quot;&#41;
                                     &#40;clojure.string/includes? &#40;str &#40;:name m&#41;&#41;
                                                               &quot;integration&quot;&#41;&#41;&#41;&#41;
                 :integration &#40;fn &#91;m&#93;
                                &#40;or &#40;clojure.string/includes? &#40;str &#40;:ns m&#41;&#41;
                                                              &quot;integration&quot;&#41;
                                    &#40;clojure.string/includes? &#40;str &#40;:name m&#41;&#41;
                                                              &quot;integration&quot;&#41;&#41;&#41;}
</code></pre><p>Enjoy! I hope this example helps you run a subset<a href='#fn-1' id='fnref1'><sup>1</sup></a> of your Clojure tests through Leiningen test selectors.</p><ol class='footnotes'><li id='fn-1'>Running a subset of your tests can be helpful and test-refresh has a few features that help you do that. If you can, I'd still recommend making all your tests fast enough to run them all the time.<a href='#fnref1'>&#8617;</a></li></ol>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2019/01/06/notifications-with-tmux-and-lein-test-refresh/index.html</id>
    <link href="https://jakemccrary.com/blog/2019/01/06/notifications-with-tmux-and-lein-test-refresh/index.html"/>
    <title><![CDATA[Notifications with tmux and lein-test-refresh]]></title>
    <updated>2019-01-06T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>I've been using Emacs in a remote <a href='https://github.com/tmux/tmux'>tmux</a> session lately and I've been missing <a href='https://github.com/jakemcc/lein-test-refresh#notifications'>lein-test-refresh</a> notifications when my Clojure tests pass or fail. Luckily, it only took me a little bit of searching to figure out a solution for when I'm working inside of tmux.</p><p>Below is a GIF of the notifications I get as my tests run and pass or fail.</p><p><img src="/images/tmux-test-refresh.gif" alt="tmux and test-refresh notifications" title="tmux and test-refresh notifications" /></p><p>With the above notifications, I can keep my focus on my code and only switch to the tmux window with <code>lein test-refresh</code> running when a test fails.</p><p>This was pretty easy to setup. You can trigger a message in tmux by running <code>tmux display-message &lt;MESSAGE&#95;HERE&gt;</code>. To configure <a href='https://github.com/jakemcc/lein-test-refresh#notifications'>lein-test-refresh</a> to send notifications to tmux simply include the following in your <code>:test-refresh</code> section of your <code>project.clj</code> or <code>profiles.clj</code>.</p><pre><code class="language-clojure">:test-refresh {:notify-command &#91;&quot;tmux&quot; &quot;display-message&quot;&#93;}
</code></pre><p>I hope you enjoy this. Its has made using a remote terminal with tmux and <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a> more enjoyable.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2018/07/16/built-in-test-narrowing-with-lein-test-refresh/index.html</id>
    <link href="https://jakemccrary.com/blog/2018/07/16/built-in-test-narrowing-with-lein-test-refresh/index.html"/>
    <title><![CDATA[Built-in test narrowing with lein-test-refresh]]></title>
    <updated>2018-07-16T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>If you follow my work you probably know that I value fast feedback cycles. Most of the open-source I maintain was developed to enable faster feedback cycles. This is why <a href='https://github.com/jakemcc/lein-test-refresh/'>lein-test-refresh</a> and <a href='https://github.com/clojure-expectations/lein-autoexpect'>lein-autoexpect</a> were originally created.</p><p>Leiningen supports <a href='https://github.com/technomancy/leiningen/blob/master/doc/TUTORIAL.md#tests'>test selectors</a> and lein-test-refresh <a href='https://github.com/jakemcc/lein-test-refresh/blob/master/CHANGES.md#040'>does as well</a>. This lets you start-up a testing session and only run tests or namespaces with certain metadata on them. This is a super useful feature as it lets you narrow your testing scope to one (or a handful) of tests while working on solving a specific problem.</p><p>lein-test-refresh now has built-in functionality that allows you to focus your test scope without restarting the Leiningen test process. If lein-test-refresh sees a <code>deftest</code> or <code>ns</code> form marked with <code>:test-refresh/focus true</code> in its metadata, then it will only run tests marked with <code>:test-refresh/focus</code>.</p><p>Below is an example of what this looks like.</p><pre><code class="language-clojure">&#40;deftest &#94;:test-refresh/focus test-addition
  &#40;is &#40;= 2 &#40;+ 1 1&#41;&#41;&#41;&#41;
</code></pre><p>This functionality has only been available for a short period of time and I've already found it useful. I think you will too. Enjoy.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2017/03/31/what-clojure-testing-library-is-most-used/index.html</id>
    <link href="https://jakemccrary.com/blog/2017/03/31/what-clojure-testing-library-is-most-used/index.html"/>
    <title><![CDATA[Which Clojure testing library is most used?]]></title>
    <updated>2017-03-31T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>I've always assumed that the built-in <code>clojure.test</code> is the most widely used testing library in the Clojure community. Earlier this month I decided to test this assumption using the Google's BigQuery <a href='https://cloud.google.com/bigquery/public-data/github'>GitHub dataset</a>.</p><p>The BigQuery GitHub dataset contains over three terabytes of source code from more than 2.8 million open source GitHub repositories. BigQuery lets us quickly query this data using SQL.</p><p>Below is a table with the results (done in early March 2017) of my investigation. Surprising no one, <code>clojure.test</code> comes out as the winner and it is a winner by a lot.  </p><pre><code>| Library      | # Repos Using |
|--------------+---------------|
| clojure.test |         14304 |
| midje        |          1348 |
| expectations |           429 |
| speclj       |           207 |
| smidjen      |             1 |
| fudje        |             1 |
</code></pre><p>23,243 repositories were identified as containing Clojure (or ClojureScript) code. This means there were about 6,953 repositories that didn't use any testing library<a href='#fn-1' id='fnref1'><sup>1</sup></a>. This puts the "no tests or an obscure other way of testing" in a pretty solid second place.</p><p>You should take these numbers as ballpark figures and not exact answers. I know from using GitHub's search interface that there are three public projects using <a href='https://github.com/jimpil/fudje'>fudje</a><a href='#fn-2' id='fnref2'><sup>2</sup></a>.</p><p>So, why don't all three of those projects show up? The dataset only includes projects where Google could identify the project as open source and the GitHub licenses API is used to do that<a href='#fn-3' id='fnref3'><sup>3</sup></a>. Two of those three projects were probably unable to be identified as something with an appropriate license.</p><p>Another small problem is that since <code>expectations</code> is an actual word, it shows up outside of <code>ns</code> declarations. I ended up using a fairly simple query to generate this data and it only knows that <code>expectations</code> shows up somewhere in a file. I experimented with some more restrictive queries but they didn't drastically change the result and I wasn't sure they weren't wrong in other ways. If you subtract a number between 100 and 150 you'll probably have a more accurate expectations usage count.</p><p>Keep reading if you want to hear more about the steps to come up with the above numbers.</p><p>If you have other Clojure questions you think could be answered by querying this dataset, let me know in the comments or on <a href='https://twitter.com/jakemcc'>twitter</a>. I have some more ideas, so I wouldn't be surprised if at least one more article gets written.</p><h2>The Details</h2><p>The process was pretty straightforward. Most of my time was spent exploring the tables, figuring out what the columns represented, figuring out what queries worked well, and manually confirming some of the results. BigQuery is very fast. Very little of my time was spent waiting for results.</p><h3>1. Setup the data</h3><p>You get 1 TB of free BigQuery usage a month. You can blow through this in a single query. Google provides sample tables that contain less data but I wanted to operate on the full set of Clojure(Script) files, so my first step was to execute some queries to create tables that only contained Clojure data.</p><p>First, I queried the <code>github&#95;repos.files</code> table for all the Clojure(Script) files and saved that to a <code>clojure.files</code> table.</p><pre><code class="language-sql">SELECT
  &#42;
FROM
  &#91;bigquery-public-data:github&#95;repos.files&#93;
WHERE
  &#40;RIGHT&#40;path, 4&#41; = '.clj'
    OR RIGHT&#40;path, 5&#41; = '.cljc'
    OR RIGHT&#40;path, 5&#41; = '.cljs'&#41;
</code></pre><p>The above query took only 9.2 seconds to run and processed 328 GB of data.</p><p>Using the <code>clojure.files</code> table, we can select the source for all the Clojure code from the <code>github&#95;repos.contents</code>. I saved this to a <code>clojure.contents</code> table.</p><pre><code class="language-sql">SELECT &#42;
FROM &#91;bigquery-public-data:github&#95;repos.contents&#93;
WHERE id IN &#40;SELECT id FROM clojure.files&#41;
</code></pre><p>This query processed 1.84 TB of data in 21.5 seconds. So fast. In just under 30 seconds, I've blown through the free limit.</p><h3>2. Identify what testing library (or libraries) a repo uses</h3><p>We can guess that a file uses a testing library if it contains certain string. The strings we'll search for are the namespaces we'd expect to see required or used in a <code>ns</code> declaration. The below query does this for each file and then rolls up the results by repository. It took 3 seconds to run and processed 611 MB of data.</p><pre><code>SELECT
  files.repo&#95;name,
  MAX&#40;uses&#95;clojure&#95;test&#41; uses&#95;clojure&#95;test,
  MAX&#40;uses&#95;expectations&#41; uses&#95;expectations,
  MAX&#40;uses&#95;midje&#41; uses&#95;midje,
  MAX&#40;uses&#95;speclj&#41; uses&#95;speclj,
  MAX&#40;uses&#95;fudje&#41; uses&#95;fudje,
  MAX&#40;uses&#95;smidjen&#41; uses&#95;smidjen,
FROM &#40;
  SELECT
    id,
    contents.content LIKE '%clojure.test%' uses&#95;clojure&#95;test,
    contents.content LIKE '%expectations%' uses&#95;expectations,
    contents.content LIKE '%midje%' uses&#95;midje,
    contents.content LIKE '%speclj%' uses&#95;speclj,
    contents.content LIKE '%fudje%' uses&#95;fudje,
    contents.content LIKE '%smidjen%' uses&#95;smidjen,
  FROM
    clojure.contents AS contents&#41; x
JOIN
  clojure.files files ON files.id = x.id
GROUP BY
  files.repo&#95;name
</code></pre><p>Below is a screenshot of the first few rows in the result.</p><p><img src="/images/bigquery-testing-library-result.png" alt="BigQuery results for test library usage by repo" title="BigQuery results for test library usage by repo" /></p><h3>3. Export the data</h3><p>At this point, we could continue doing the analysis using SQL and the BigQuery UI but I opted to explore the data using Clojure and the repl. There were too many rows to directly download the query results as a csv file, so I ended up having to save the results as a table and then export it to Google's cloud storage and download from there.</p><p>The first few rows of the file look like this:</p><pre><code>files&#95;repo&#95;name,uses&#95;clojure&#95;test,uses&#95;expectations,uses&#95;midje,uses&#95;speclj,uses&#95;fudje,uses&#95;smidjen
wangchunyang/clojure-liberator-examples,true,false,false,false,false,false
yantonov/rex,false,false,false,false,false,false
</code></pre><h3>4. Calculate some numbers</h3><p>The code takes the csv file and does some transformations. You could do this in Excel or using any language of your choice. I'm not going to include code here, as it isn't that interesting.</p><h2>BigQuery thoughts</h2><p>This was my first time using Google's BigQuery. This wasn't the most difficult analysis to do but I was impressed at the speed and ease of use. The web UI, which I used entirely for this, is neither really great or extremely terrible. It mostly just worked and I rarely had to look up documentation.</p><p>I don't really feel comfortable making a judgment call on if the cost is expensive or not but this article cost a bit less than seven dollars to write. This doesn't seem too outrageous to me.</p><p>Based on my limited usage of BigQuery, it is something I'd look into further if I needed its capabilities. <ol class='footnotes'><li id='fn-1'>Probably higher, as projects can and use more than one testing library.<a href='#fnref1'>&#8617;</a></li><li id='fn-2'>And those projects are <a href='https://github.com/jumarko/clojure-random'>jumarko/clojure-random</a>, <a href='https://github.com/dpassen1/great-sort'>dpassen1/great-sort</a>, and <a href='https://github.com/jimpil/fudje'>jimpil/fudje</a>.<a href='#fnref2'>&#8617;</a></li><li id='fn-3'><a href='https://news.ycombinator.com/item?id=12004644'>Source is a Google Developer Advocate's response on old HN post</a><a href='#fnref3'>&#8617;</a></li></ol></p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2017/02/27/using-lein-test-refresh-with-expectations/index.html</id>
    <link href="https://jakemccrary.com/blog/2017/02/27/using-lein-test-refresh-with-expectations/index.html"/>
    <title><![CDATA[Using lein-test-refresh with expectations]]></title>
    <updated>2017-02-27T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>The 2.2.0 release<a href='#fn-1' id='fnref1'><sup>1</sup></a> of <a href='https://github.com/clojure-expectations/expectations/blob/master/CHANGELOG.md#changes-in-version-220'>expectations</a> adds a <code>clojure.test</code> <a href='https://clojure-expectations.github.io/clojure-test.html'>compatible syntax</a>. The release adds the <code>defexpect</code> macro which forces you to name your test but then generates code that is compatible with <code>clojure.test</code>.</p><p>Why would you want this? Because <code>clojure.test</code> is the built-in testing library for Clojure, an entire ecosystem has been built around it. Tool support for <code>clojure.test</code> is always going to be ahead of support for the original <code>expectations</code>. By using the new <code>clojure.test</code> compatible syntax, <code>expectations</code> can take advantage of all the tools built for <code>clojure.test</code>.</p><h3>Using lein-test-refresh with expectations</h3><p>If you move to the new <code>clojure.test</code> compatible syntax, you can start using <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a> to automatically rerun your tests when your code changes. <code>lein-test-refresh</code> is a fork of the original expectations autorunner, <a href='https://github.com/clojure-expectations/lein-autoexpect'>lein-autoexpect</a>, but it has grown to have more features than its original inspiration. Now you can use it with <code>expectations</code><a href='#fn-2' id='fnref2'><sup>2</sup></a>.</p><p>Below is a sample <code>project.clj</code> that uses <code>lein-test-refresh</code> with the latest expectations.</p><pre><code class="language-clojure">&#40;defproject expectations-project &quot;0.1.0-SNAPSHOT&quot;
  :description &quot;Sample project using expectations&quot;
  :dependencies &#91;&#91;org.clojure/clojure &quot;1.8.0&quot;&#93;&#93;
  :plugins &#91;&#91;com.jakemccrary/lein-test-refresh  &quot;0.18.1&quot;&#93;&#93;
  :profiles {:dev {:dependencies &#91;&#91;expectations &quot;2.2.0-beta1&quot;&#93;&#93;}}&#41;
</code></pre><p>Here is an example test file.</p><pre><code class="language-clojure">&#40;ns expectations-project.core-test
  &#40;:require &#91;expectations :refer :all&#93;
            &#91;expectations.clojure.test :refer &#91;defexpect&#93;&#93;&#41;&#41;

&#40;defexpect two
  2 &#40;+ 1 1&#41;&#41;

&#40;defexpect three
  3 &#40;+ 1 1&#41;&#41;

&#40;defexpect group
  &#40;expect &#91;1 2&#93; &#40;conj &#91;&#93; 1 5&#41;&#41;
  &#40;expect #{1 2} &#40;conj #{} 1 2&#41;&#41;
  &#40;expect {1 2} &#40;assoc {} 1 3&#41;&#41;&#41;
</code></pre><p>And here is the result of running <code>lein test-refresh</code>.</p><pre><code>$ lein test-refresh
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42; Running tests &#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
:reloading &#40;expectations-project.core-test&#41;

FAIL in &#40;group&#41; &#40;expectations&#95;project/core&#95;test.clj:11&#41;
expected: &#91;1 2&#93;
  actual: &#91;1 5&#93; from &#40;conj &#91;&#93; 1 5&#41;

FAIL in &#40;group&#41; &#40;expectations&#95;project/core&#95;test.clj:11&#41;
expected: {1 2}
  actual: {1 3} from &#40;assoc {} 1 3&#41;

FAIL in &#40;three&#41; &#40;expectations&#95;project/core&#95;test.clj:8&#41;
expected: 3
  actual: 2 from &#40;+ 1 1&#41;

Ran 3 tests containing 5 assertions.n
3 failures, 0 errors.

Failed 3 of 5 assertions
Finished at 11:53:06.281 &#40;run time: 0.270s&#41;
</code></pre><p>After some quick edits to fix the test errors and saving the file, here is the output from the tests re-running.</p><pre><code>&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42; Running tests &#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
:reloading &#40;expectations-project.core-test&#41;

Ran 3 tests containing 5 assertions.
0 failures, 0 errors.
:reloading &#40;&#41;

Ran 3 tests containing 5 assertions.
0 failures, 0 errors.

Passed all tests
Finished at 11:53:59.045 &#40;run time: 0.013s&#41;
</code></pre><p>If you're using <code>expectations</code> and switch to the new <code>clojure.test</code> compatible syntax, I'd encourage you to start using <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a>.</p><ol class='footnotes'><li id='fn-1'>As of 2016-02-27 <code>2.2.0</code> isn't out yet, but <code>2.2.0-beta1</code> has been released and has the changes.<a href='#fnref1'>&#8617;</a></li><li id='fn-2'>In fact, you have to use it if you use Leiningen and the new syntax and want your tests to run automatically.<a href='#fnref2'>&#8617;</a></li></ol>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2016/06/20/my-recommended-clojure-testing-setup/index.html</id>
    <link href="https://jakemccrary.com/blog/2016/06/20/my-recommended-clojure-testing-setup/index.html"/>
    <title><![CDATA[My recommended Clojure testing setup]]></title>
    <updated>2016-06-20T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>Occasionally, either on Stack Overflow or in the <a href='http://clojurians.net/'>Clojurians</a> Slack group, someone will ask what tools they should use to test Clojure code. Below is what I would currently recommend. I've come to this recommendation through observing teams using a variety of testing tools and through my own use them.</p><blockquote><p> Use clojure.test with  <a href='https://github.com/pjstadig/humane-test-output'>humane-test-output</a>  and <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a>. </p></blockquote><h3>Use clojure.test</h3><p>clojure.test is ubiquitous and not a big departure from other languages' testing libraries. It has its warts but your team will be able to understand it quickly and will be able to write maintainable tests.</p><h3>Use humane-test-output</h3><p>You should use clojure.test with <a href='https://github.com/pjstadig/humane-test-output'>humane-test-output</a>. Together they provide a testing library that has minimal additional syntax and good test failure reporting.</p><h3>Use lein-test-refresh</h3><p>If you're not using a tool that reloads and reruns your tests on file changes then you are wasting your time. The delay between changing code and seeing test results is drastically reduced by using a tool like <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a>. Nearly everyone I know who tries adding lein-test-refresh to their testing toolbox continues to use it. Many of these converts were not newcomers to Clojure either, they had years of experience and had already developed workflows that worked for them.</p><h3>Use lein-test-refresh's advanced features</h3><p><a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a> makes development better even if you don't change any of its settings. It gets even better if you use some of its advanced features.</p><p>Below is a stripped down version of my <code>&#126;/.lein/profiles.clj</code>. The <code>:test-refresh</code> key points towards my recommended lein-test-refresh settings.</p><pre><code class="language-clojure">{:user {:dependencies &#91;&#91;pjstadig/humane-test-output &quot;0.8.0&quot;&#93;&#93;
        :injections &#91;&#40;require 'pjstadig.humane-test-output&#41;
                     &#40;pjstadig.humane-test-output/activate!&#41;&#93;
        :plugins &#91;&#91;com.jakemccrary/lein-test-refresh &quot;0.16.0&quot;&#93;&#93;
        :test-refresh {:notify-command &#91;&quot;terminal-notifier&quot; &quot;-title&quot; &quot;Tests&quot; &quot;-message&quot;&#93;
                       :quiet true
                       :changes-only true}}}
</code></pre><p>These settings turn on notifications when my tests finish running (<code>:notify-command</code> setting), make clojure.test's output less verbose (<code>:quiet true</code>), and only run tests in namespaces affected by the previous code change (<code>:changes-only true</code>). These three settings give me the quickest feedback possible and free me from having the terminal running <code>lein test-refresh</code> visible.</p><p>Quick feedback lets you make changes faster. If you're going to write tests, and you should write tests, having them run quickly is powerful. After years of writing Clojure, this is my current go-to for testing Clojure code and getting extremely fast feedback.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2015/12/18/even-quicker-feedback-from-your-clojure-tests/index.html</id>
    <link href="https://jakemccrary.com/blog/2015/12/18/even-quicker-feedback-from-your-clojure-tests/index.html"/>
    <title><![CDATA[Even quicker feedback from your Clojure tests]]></title>
    <updated>2015-12-18T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>I was recently inspired by a post on a mailing list to make the TDD cycle with <code>clojure.test</code> and <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a> even faster. <code>lein-test-refresh</code> is a Leiningen tool that monitors your Clojure project's source, reloads changes, and then runs your tests. Tools like it provide some of the fastest feedback cycles possible.</p><p>To make the feedback cycle even faster I added the option to only run tests in changed namespaces. This means you're running the minimum number of tests after a change. Version 0.12.0 of <code>lein-test-refresh</code> was released earlier this week with this feature.</p><p>To use it add <code>&#91;com.jakemccrary/lein-test-refresh 0.12.0&#93;</code> as a plugin to your profiles.clj or project.clj. An example <a href='https://github.com/jakemcc/lein-test-refresh/blob/master/sample.project.clj#L3'>project.clj</a> can be found in the project's GitHub repo.</p><p>Once you're on the latest version you can toggle this feature from the command line by providing a <code>:changes-only</code> flag, `lein test-refresh :changes-only<code>, or by adding </code>:changes-only true` to your <code>:test-refresh</code> configuration section in your project.clj or profiles.clj. When the feature is on you can still run all your tests by hitting <code>enter</code> in the terminal running <code>lein test-refresh</code>.</p><p>Below is an example of the time difference between running all my tests and the tests in a single namespace.</p><pre><code>Ran 49 tests containing 219 assertions.
0 failures, 0 errors.

Passed all tests
Finished at 14:42:41.655 &#40;run time: 2.006s&#41;
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42; Running tests &#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;&#42;
:reloading &#40;lumanu.utils-test&#41;

Ran 1 tests containing 3 assertions.
0 failures, 0 errors.

Passed all tests
Finished at 14:43:12.648 &#40;run time: 0.085s&#41;
</code></pre><p>I've been using this feature for about a week now and am enjoying it. My whole test suite isn't particularly slow but even still I've been enjoying the faster feedback.</p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2015/04/25/quieter-clojure-dot-test-output/index.html</id>
    <link href="https://jakemccrary.com/blog/2015/04/25/quieter-clojure-dot-test-output/index.html"/>
    <title><![CDATA[Quieter clojure.test output]]></title>
    <updated>2015-04-25T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>If you use <code>clojure.test</code> then there is a good chance you've been annoyed by all the <a href='https://github.com/jakemcc/lein-test-refresh/issues/33'>output</a> when you run your tests in the terminal. When there is a test failure you have to scroll through pages of output to find the error.</p><p>With release <code>0.9.0</code> of <a href='https://github.com/jakemcc/lein-test-refresh'>lein-test-refresh</a> you can minimize the output of <code>clojure.test</code> and <strong>only</strong> see failure and summary messages. To enable this feature add <code>:quiet true</code> to the <code>:test-refresh</code> configuration map in either your project.clj or profiles.clj file. If you configure <code>lein-test-refresh</code> in <code>&#126;/.lein/profiles.clj</code> then turning on this feature looks like the following. <a href='#fn-1' id='fnref1'><sup>1</sup></a></p><pre><code class="language-clojure">{:user {:plugins &#91;&#91;com.jakemccrary/lein-test-refresh &quot;0.9.0&quot;&#93;&#93;
        :test-refresh {:quiet true}}}
</code></pre><p>Setting up your profiles.clj like above allows you to move to Clojure project in your terminal, run <code>lein test-refresh</code>, and have your <code>clojure.test</code>s run whenever a file changes. In addition, your terminal won't show the usual <i>Testing a.namespace</i> output.</p><p>Below is what you typically see when running <code>clojure.test</code> tests in a terminal. I had to cut most of the <i>Testing a.namespace</i> messages from the picture.</p><p><img src="/images/not-quiet-test-output.png" alt="Normal view of test output" /></p><p>The following picture is with quiet mode turned on in <code>lein-test-refresh</code>. No more <i>Testing a.namespace</i> messages! No more scrolling through all your namespaces to find the failure!</p><p><img src="/images/minimal-test-output.png" alt="Minimal output in console" /></p><p>I just released this feature so i haven't had a chance to use it too much. I imagine it may evolve to change the output more. <ol class='footnotes'><li id='fn-1'>More configuration options can be found <a href='https://github.com/jakemcc/lein-test-refresh/blob/master/sample.project.clj#L5-L24'>here</a><a href='#fnref1'>&#8617;</a></li></ol></p>]]></content>
  </entry>
  <entry>
    <id>https://jakemccrary.com/blog/2014/06/22/comparing-clojure-testing-libraries-output/index.html</id>
    <link href="https://jakemccrary.com/blog/2014/06/22/comparing-clojure-testing-libraries-output/index.html"/>
    <title><![CDATA[Comparing Clojure Testing Libraries: Output]]></title>
    <updated>2014-06-22T23:59:59+00:00</updated>
    <content type="html"><![CDATA[<p>I recently became interested in how Clojure testing libraries help you when there is a test failure. This interest resulted in me <a href='https://github.com/jakemcc/clojure-test-bed'>exploring</a> different Clojure testing libraries. I created the same tests using <strong>clojure.test</strong> (with and without <a href='https://github.com/pjstadig/humane-test-output'>humane-test-output</a>), <a href='http://jayfields.com/expectations/'>expectations</a>, <a href='https://github.com/marick/Midje'>Midje</a>, and <a href='http://speclj.com/'>Speclj</a> and looked at the output.</p><p>I ran all of these examples using Leiningen. <strong>Midje</strong>, <strong>Speclj</strong>, and <strong>expectations</strong> color their output but I'm not going to try to reproduce that here. The color added by <strong>Midje</strong> and <strong>expectations</strong> is useful. <strong>Speclj</strong> color hurt its readability. I use a dark colored terminal and <strong>Speclj</strong> colors the line that tells where the failure occurs black. This made it hard to read.</p><p>I'm not going to show what the tests look like for each testing library past the first comparison. How a test in expressed is important but not what I want to focus on in this post.</p><h2>Comparing Strings</h2><p>Going to start off with a basic string comparison. The failing test compares two strings that only differ by one character.</p><h5>clojure.test</h5><p>Most (hopefully all) Clojure programmers should be familiar with <strong>clojure.test</strong>. It is the testing library that is included with Clojure.</p><pre><code class="language-clojure">&#40;ns example.string-test
  &#40;:require &#91;clojure.test :refer :all&#93;&#41;&#41;

&#40;deftest string-comparisons
  &#40;is &#40;= &quot;strings equal&quot; &quot;strings equal&quot;&#41;&#41;
  &#40;is &#40;= &quot;space&quot; &quot;spice&quot;&#41;&#41;&#41;
</code></pre><p>The output below is what you get when the above test runs. Even in this simple example it isn't the easiest to read. It doesn't make it easy to find the expected or actual values.</p><pre><code class="language-console clojure.test output">FAIL in &#40;string-comparisons&#41; &#40;string&#95;test.clj:6&#41;
expected: &#40;= &quot;space&quot; &quot;spice&quot;&#41;
  actual: &#40;not &#40;= &quot;space&quot; &quot;spice&quot;&#41;&#41;
</code></pre><p>Below is the same test but with <strong>humane-test-output</strong> enabled. It is easy to read the output and see the expected and actual value. It even provides a diff between them although in this situation it isn't that useful.</p><pre><code class="language-console clojure.test with humane-test-output">FAIL in &#40;string-comparisons&#41; &#40;string&#95;test.clj:6&#41;
expected: &quot;space&quot;
  actual: &quot;spice&quot;
    diff: - &quot;space&quot;
          + &quot;spice&quot;
</code></pre><h5>expectations</h5><p>Another testing library is Jay Field's <a href='http://jayfields.com/expectations/'>expectations</a>. You can see from the example that it has a fairly minimal syntax.</p><pre><code class="language-clojure">&#40;ns example.string-expectations
  &#40;:require &#91;expectations :refer :all&#93;&#41;&#41;

&#40;expect &quot;strings equal&quot; &quot;strings equal&quot;&#41;
&#40;expect &quot;space&quot; &quot;spice&quot;&#41;
</code></pre><pre><code class="language-console expectations output">failure in &#40;string&#95;expectations.clj:5&#41; : example.string-expectations
&#40;expect &quot;space&quot; &quot;spice&quot;&#41;

           expected: &quot;space&quot;
                was: &quot;spice&quot;

           matches: &quot;sp&quot;
           diverges: &quot;ace&quot;
                  &amp;: &quot;ice&quot;
</code></pre><p>The output from <strong>expectations</strong> is very readable. You can easily pick out the expected and actual values. It also shows you where the string starts to diverge.</p><h5>Speclj</h5><p>Before writing this post I had zero experience with Micah Martin's <a href='http://speclj.com/'>Speclj</a>. Below is my translation of the failing string test and its output.</p><pre><code class="language-clojure">&#40;ns example.string-spec
  &#40;:require &#91;speclj.core :refer :all&#93;&#41;&#41;

&#40;describe &quot;String comparisons&quot;
  &#40;it &quot;have nice error message&quot;
      &#40;should= &quot;space&quot; &quot;spice&quot;&#41;&#41;&#41;
</code></pre><pre><code class="language-console Speclj">9&#41; String comparisons have nice error message
   Expected: &quot;space&quot;
        got: &quot;spice&quot; &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/string&#95;spec.clj:7
</code></pre><p><strong>Speclj</strong>'s test output above is an improvement over <strong>clojure.test</strong>. You can easily find the expected and actual values. It doesn't provide any help with diagnosing how those values are different.</p><h5>Midje</h5><p>I have a little bit of experience with Brian Marick's <a href='https://github.com/marick/Midje'>Midje</a>. Unlike the other libraries it switches up the assertion syntax. In <strong>Midje</strong> the expected value is on the right side of <code>=&gt;</code>.</p><pre><code class="language-clojure">&#40;ns example.string-test
  &#40;:require &#91;midje.sweet :refer :all&#93;&#41;&#41;

&#40;fact &quot;strings are equal&quot;
  &quot;string is equal&quot; =&gt; &quot;string is equal&quot;&#41;

&#40;fact &quot;strings not equal&quot;
   &quot;spice&quot; =&gt; &quot;space&quot;&#41;
</code></pre><pre><code class="language-console Midje">FAIL &quot;strings not equal&quot; at &#40;string&#95;test.clj:8&#41;
    Expected: &quot;space&quot;
      Actual: &quot;spice&quot;
</code></pre><p><strong>Midje</strong>'s output is similar to <strong>Speclj</strong>'s. You can quickly find the expected and actual values but it doesn't help you spot the difference.</p><h3>String Comparison Winner</h3><p><strong>expectations</strong> wins for best output. You can easily spot the expected and actual values and it also helps you find the difference between the strings.</p><p>The worst output comes from <strong>clojure.test</strong>. It doesn't make it easy to spot the difference or even find the expected and actual values.</p><h2>Comparing Maps</h2><p>For maps I've setup three assertions. The first has an extra key-value pair in the actual value. The second has an extra in the expected value. The final assertion has a different value for the <code>:cheese</code> key. The <strong>clojure.test</strong> example is below.</p><pre><code class="language-clojure">&#40;deftest map-comparisons
  &#40;is &#40;= {:sheep 1} {:cheese 1 :sheep 1}&#41;&#41;
  &#40;is &#40;= {:sheep 1 :cheese 1} {:sheep 1}&#41;&#41;
  &#40;is &#40;= {:sheep 1 :cheese 1} {:sheep 1 :cheese 5}&#41;&#41;&#41;
</code></pre><pre><code class="language-console clojure.test">FAIL in &#40;map-comparisons&#41; &#40;map&#95;test.clj:5&#41;
expected: &#40;= {:sheep 1} {:cheese 1, :sheep 1}&#41;
  actual: &#40;not &#40;= {:sheep 1} {:cheese 1, :sheep 1}&#41;&#41;

FAIL in &#40;map-comparisons&#41; &#40;map&#95;test.clj:6&#41;
expected: &#40;= {:sheep 1, :cheese 1} {:sheep 1}&#41;
  actual: &#40;not &#40;= {:cheese 1, :sheep 1} {:sheep 1}&#41;&#41;

FAIL in &#40;map-comparisons&#41; &#40;map&#95;test.clj:7&#41;
expected: &#40;= {:sheep 1, :cheese 1} {:sheep 1, :cheese 5}&#41;
  actual: &#40;not &#40;= {:cheese 1, :sheep 1} {:cheese 5, :sheep 1}&#41;&#41;
</code></pre><p>Unsurprisingly the default <strong>clojure.test</strong> output for maps suffers from the same problems found in the string comparisons. To find the actual and expected values you need to manually parse the output.</p><pre><code class="language-console clojure.test with humane-test-output">FAIL in &#40;map-comparisons&#41; &#40;map&#95;test.clj:5&#41;
expected: {:sheep 1}
  actual: {:cheese 1, :sheep 1}
    diff: + {:cheese 1}

FAIL in &#40;map-comparisons&#41; &#40;map&#95;test.clj:6&#41;
expected: {:cheese 1, :sheep 1}
  actual: {:sheep 1}
    diff: - {:cheese 1}

FAIL in &#40;map-comparisons&#41; &#40;map&#95;test.clj:7&#41;
expected: {:cheese 1, :sheep 1}
  actual: {:cheese 5, :sheep 1}
    diff: - {:cheese 1}
          + {:cheese 5}
</code></pre><p>Above is the output of using <strong>clojure.test</strong> with <strong>humane-test-output</strong>. It is a big improvement over the default <strong>clojure.test</strong>. You can quickly see the expected and actual values. Unlike with the string assertions the diff view is actually helpful. The diffs do a good job of helping you identify the error.</p><pre><code class="language-console expectations">failure in &#40;map&#95;expectations.clj:6&#41; : example.map-expectations
&#40;expect {:sheep 1} {:sheep 1, :cheese 1}&#41;

           expected: {:sheep 1}
                was: {:cheese 1, :sheep 1}

           in expected, not actual: null
           in actual, not expected: {:cheese 1}

failure in &#40;map&#95;expectations.clj:7&#41; : example.map-expectations
&#40;expect {:sheep 1, :cheese 1} {:sheep 1}&#41;

           expected: {:cheese 1, :sheep 1}
                was: {:sheep 1}

           in expected, not actual: {:cheese 1}
           in actual, not expected: null

failure in &#40;map&#95;expectations.clj:8&#41; : example.map-expectations
&#40;expect {:sheep 1, :cheese 5} {:sheep 1, :cheese 1}&#41;

           expected: {:cheese 5, :sheep 1}
                was: {:cheese 1, :sheep 1}

           in expected, not actual: {:cheese 5}
           in actual, not expected: {:cheese 1}
</code></pre><p><strong>expectations</strong> does a pretty good job helping you as well. As before, you can clearly read the expected and actual values. <strong>expectations</strong> also provides some hint as to what is different between the maps. I find the English descriptions a bit easier to read than <strong>humane-test-output</strong>'s diff view. Still seeing lines like line 7 (`in expected, not actual: null`) is a bit confusing and the output would be improved if it was suppressed.</p><p>I'm just going to lump <strong>Speclj</strong> and <strong>Midje</strong> together. The output for each is below. They both improve over <strong>clojure.test</strong> by making it easy to see the expected and actual value. They both don't do anything beyond that.</p><pre><code class="language-console Speclj">4&#41; map comparisons have nice error messages when extra entries keys present
   Expected: {:sheep 1}
        got: {:cheese 1, :sheep 1} &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/map&#95;spec.clj:7

5&#41; map comparisons have nice error messages when missing an entry
   Expected: {:cheese 1, :sheep 1}
        got: {:sheep 1} &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/map&#95;spec.clj:9

6&#41; map comparisons have nice error messages when mismatched values
   Expected: {:cheese 5, :sheep 1}
        got: {:cheese 1, :sheep 1} &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/map&#95;spec.clj:11
</code></pre><pre><code class="language-console Midje">FAIL &quot;map is missing an entry&quot; at &#40;map&#95;test.clj:5&#41;
    Expected: {:cheese 1, :sheep 1}
      Actual: {:sheep 1}

FAIL &quot;map has an extra entry&quot; at &#40;map&#95;test.clj:8&#41;
    Expected: {:sheep 1}
      Actual: {:cheese 1, :sheep 1}

FAIL &quot;map has a different value&quot; at &#40;map&#95;test.clj:11&#41;
    Expected: {:cheese 5, :sheep 1}
      Actual: {:cheese 1, :sheep 1}
</code></pre><h3>Map Comparison Winner</h3><p>Tie between <strong>humane-test-output</strong> and <strong>expectations</strong>. Both do a good job of helping the reader spot the difference.</p><h2>Comparing Sets</h2><p>Next up are sets. Only two assertions for this section. One with the actual value having an extra member and one test where it is missing a member.</p><pre><code class="language-clojure">&#40;ns example.set-test
  &#40;:require &#91;clojure.test :refer :all&#93;&#41;&#41;

&#40;deftest set-comparisons
  &#40;is &#40;= #{:a :b} #{:a :b :c}&#41;&#41;
  &#40;is &#40;= #{:a :b :c} #{:a :b}&#41;&#41;&#41;
</code></pre><p>First up is the basic <strong>clojure.test</strong> output. It suffers from the same problem it has suffered this entire time. It doesn't make it easy to read the expected and actual values. </p><pre><code class="language-console clojure.test">FAIL in &#40;set-comparisons&#41; &#40;set&#95;test.clj:5&#41;
expected: &#40;= #{:b :a} #{:c :b :a}&#41;
  actual: &#40;not &#40;= #{:b :a} #{:c :b :a}&#41;&#41;

FAIL in &#40;set-comparisons&#41; &#40;set&#95;test.clj:6&#41;
expected: &#40;= #{:c :b :a} #{:b :a}&#41;
  actual: &#40;not &#40;= #{:c :b :a} #{:b :a}&#41;&#41;
</code></pre><p>No surprises with <strong>humane-test-output</strong>. It improves the <strong>clojure.test</strong> output by making it easy to read the expected and actual values. The diff view also helps figure out what is causing the assertion to fail.</p><pre><code class="language-console clojure.test with humane-test-output">FAIL in &#40;set-comparisons&#41; &#40;set&#95;test.clj:5&#41;
expected: #{:b :a}
  actual: #{:c :b :a}
    diff: + #{:c}

FAIL in &#40;set-comparisons&#41; &#40;set&#95;test.clj:6&#41;
expected: #{:c :b :a}
  actual: #{:b :a}
    diff: - #{:c}
</code></pre><p><strong>expectations</strong> once again delivers nice output. It continues to be easy to find the expected and actual values and helps you spot the differences with a diff view.</p><pre><code class="language-console expectations">failure in &#40;set&#95;expectations.clj:4&#41; : example.set-expectations
&#40;expect #{:b :a} #{:c :b :a}&#41;

           expected: #{:b :a}
                was: #{:c :b :a}

           in expected, not actual: null
           in actual, not expected: #{:c}

failure in &#40;set&#95;expectations.clj:5&#41; : example.set-expectations
&#40;expect #{:c :b :a} #{:b :a}&#41;

           expected: #{:c :b :a}
                was: #{:b :a}

           in expected, not actual: #{:c}
           in actual, not expected: null
</code></pre><p><strong>Speclj</strong> and <strong>Midje</strong> both have better output than the basic <strong>clojure.test</strong>.</p><pre><code class="language-console Speclj">7&#41; set comparisons have nice error messages when missing item
   Expected: #{:b :a}
        got: #{:c :b :a} &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/set&#95;spec.clj:9

8&#41; set comparisons have nice error messages when more items
   Expected: #{:c :b :a}
        got: #{:b :a} &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/set&#95;spec.clj:11
</code></pre><pre><code class="language-console Midje">FAIL &quot;set is superset of expected&quot; at &#40;set&#95;test.clj:5&#41;
    Expected: #{:a :b}
      Actual: #{:a :b :c}

FAIL &quot;set is subset of expected&quot; at &#40;set&#95;test.clj:8&#41;
    Expected: #{:a :b :c}
      Actual: #{:a :b}
</code></pre><h3>Set Comparison Winner</h3><p>Similar to the winner of the map comparisons I'm going to split the victory between <strong>expectations</strong> and <strong>humane-test-output</strong>.</p><h2>Comparing Lists</h2><p>Next up we compare lists (and lists to vectors). There are three comparisons; one with an extra element, one with same length but a mismatched element, and one comparing a vector and list with drastically different contents.</p><pre><code class="language-clojure">&#40;ns example.seq-test
  &#40;:require &#91;clojure.test :refer :all&#93;&#41;&#41;

&#40;deftest list-comparisons
  &#40;is &#40;= '&#40;1 2 3&#41; '&#40;1 2 3 4&#41;&#41;&#41;
  &#40;is &#40;= '&#40;1 2 4&#41; '&#40;1 2 3&#41;&#41;&#41;
  &#40;is &#40;= '&#40;9 8 7&#41; &#91;1 2 3&#93;&#41;&#41;&#41;
</code></pre><p>First up <strong>clojure.test</strong>. Same issues as with all the previous comparisons.</p><pre><code class="language-console clojure.test">FAIL in &#40;list-comparisons&#41; &#40;seq&#95;test.clj:5&#41;
expected: &#40;= &#40;quote &#40;1 2 3&#41;&#41; &#40;quote &#40;1 2 3 4&#41;&#41;&#41;
  actual: &#40;not &#40;= &#40;1 2 3&#41; &#40;1 2 3 4&#41;&#41;&#41;

FAIL in &#40;list-comparisons&#41; &#40;seq&#95;test.clj:6&#41;
expected: &#40;= &#40;quote &#40;1 2 4&#41;&#41; &#40;quote &#40;1 2 3&#41;&#41;&#41;
  actual: &#40;not &#40;= &#40;1 2 4&#41; &#40;1 2 3&#41;&#41;&#41;

FAIL in &#40;list-comparisons&#41; &#40;seq&#95;test.clj:7&#41;
expected: &#40;= &#40;quote &#40;9 8 7&#41;&#41; &#91;1 2 3&#93;&#41;
  actual: &#40;not &#40;= &#40;9 8 7&#41; &#91;1 2 3&#93;&#41;&#41;
</code></pre><p>Once again <strong>humane-test-output</strong> improves upon <strong>clojure.test</strong>. Only interesting difference from previous comparisons is that the diff view ends up having <code>nil</code> values in it where the elements are the same.</p><pre><code class="language-console clojure.test with humane-test-output">FAIL in &#40;list-comparisons&#41; &#40;seq&#95;test.clj:5&#41;
expected: &#40;1 2 3&#41;
  actual: &#40;1 2 3 4&#41;
    diff: + &#91;nil nil nil 4&#93;

FAIL in &#40;list-comparisons&#41; &#40;seq&#95;test.clj:6&#41;
expected: &#40;1 2 4&#41;
  actual: &#40;1 2 3&#41;
    diff: - &#91;nil nil 4&#93;
          + &#91;nil nil 3&#93;

FAIL in &#40;list-comparisons&#41; &#40;seq&#95;test.clj:7&#41;
expected: &#40;9 8 7&#41;
  actual: &#91;1 2 3&#93;
    diff: - &#91;9 8 7&#93;
          + &#91;1 2 3&#93;
</code></pre><p><strong>expectations</strong> continues to have good output. It tries to help you out as well. You'll notice that it also has <code>nil</code> values inserted where the lists are the same.</p><pre><code class="language-console expectations">failure in &#40;list&#95;expectations.clj:4&#41; : example.list-expectations
&#40;expect '&#40;1 2 3&#41; '&#40;1 2 3 4&#41;&#41;

           expected: &#40;1 2 3&#41;
                was: &#40;1 2 3 4&#41;

           in expected, not actual: null
           in actual, not expected: &#91;nil nil nil 4&#93;
           actual is larger than expected

failure in &#40;list&#95;expectations.clj:5&#41; : example.list-expectations
&#40;expect '&#40;1 2 4&#41; '&#40;1 2 3&#41;&#41;

           expected: &#40;1 2 4&#41;
                was: &#40;1 2 3&#41;

           in expected, not actual: &#91;nil nil 4&#93;
           in actual, not expected: &#91;nil nil 3&#93;

failure in &#40;list&#95;expectations.clj:6&#41; : example.list-expectations
&#40;expect '&#40;9 8 7&#41; &#91;1 2 3&#93;&#41;

           expected: &#40;9 8 7&#41;
                was: &#91;1 2 3&#93;

           in expected, not actual: &#91;9 8 7&#93;
           in actual, not expected: &#91;1 2 3&#93;
</code></pre><p>Unsurprisingly, <strong>Speclj</strong> and <strong>Midje</strong> are better than <strong>clojure.test</strong> but again don't go beyond making easy to find the expected and actual values.</p><pre><code class="language-console Speclj">1&#41; List/vector comparisons when there is an extra element
   Expected: &#40;1 2 3&#41;
        got: &#40;1 2 3 4&#41; &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/string&#95;spec.clj:7

2&#41; List/vector comparisons when there is a mismatched element
   Expected: &#40;1 2 4&#41;
        got: &#40;1 2 3&#41; &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/string&#95;spec.clj:9

3&#41; List/vector comparisons when comparing different types
   Expected: &#40;9 8 7&#41;
        got: &#91;1 2 3&#93; &#40;using =&#41;
   /Users/jake/src/jakemcc/example/spec/example/string&#95;spec.clj:11
</code></pre><pre><code class="language-console Midje">FAIL &quot;lists are different sizes&quot; at &#40;seq&#95;test.clj:5&#41;
    Expected: &#40;1 2 3&#41;
      Actual: &#40;1 2 3 4&#41;

FAIL &quot;lists have different entries&quot; at &#40;seq&#95;test.clj:8&#41;
    Expected: &#40;1 2 4&#41;
      Actual: &#40;1 2 3&#41;

FAIL &quot;compare very different list like values&quot; at &#40;seq&#95;test.clj:14&#41;
    Expected: &#40;9 8 7&#41;
      Actual: &#91;1 2 3&#93;
</code></pre><h3>List Comparison Winner</h3><p>I find the <strong>clojure.test</strong> with <strong>humane-test-output</strong> to be a bit easier to read than <strong>expectations</strong>. Both have better output than the basic <strong>clojure.test</strong>, <strong>Speclj</strong>, and <strong>Midje</strong>.</p><h2>Overall Winner</h2><p>If I were picking a testing library based entirely on what a failing test looks like I would use <strong>expectations</strong>. My second pick would be <strong>clojure.test</strong> with <strong>humane-test-output</strong>.</p><p>It is great that Clojure ships with <strong>clojure.test</strong>. It is unfortunate that it does so little to help you read a failing test. Every library I tried has better output than <strong>clojure.test</strong>.</p><h3>Addendum</h3><p><i>Added 2014/06/23</i></p><p>Colin Jones <a href='http://jakemccrary.com/blog/2014/06/22/comparing-clojure-testing-libraries-output/#comment-1449451549'>points out</a> that Speclj provides <code>should==</code>. <code>should==</code> checks that the expected and actual value have the same contents. He provided a <a href='https://gist.github.com/trptcolin/7e1ece5179581085730f'>gist</a> that shows the difference.</p>]]></content>
  </entry>
</feed>
